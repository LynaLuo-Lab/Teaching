{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sklearn as skl\n",
    "from scipy.optimize import minimize\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly as ply\n",
    "import tqdm\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import scipy as sp\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, let's setup a small symmetric potential (you can modify the shape, but keep the energy barrier ~1kT, so your test simulation will converge faster) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a*x^6-b*x^2 has minima in x =+-1 and a barrier at x=0\n",
    "# The ratio a/b can must be tuned depending on the kT used in the brownian dynamics, so that the barrier can be crossed repeatedly.\n",
    "\n",
    "def potFun(x):\n",
    "    return(0.05*((1/2000)*(x)**6-(x)**2))\n",
    "def potGradFun(x):\n",
    "    return(0.05*((6.0/2000)*(x)**5-2.0*(x)))\n",
    "\n",
    "xgrid=np.linspace(-6,6,25)\n",
    "sns.scatterplot(\n",
    "    x=xgrid,\n",
    "    y=potFun(xgrid),\n",
    "    label='U(X) (kcal/mol)'\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=xgrid,\n",
    "    y=potGradFun(xgrid),\n",
    "    label='grad(U(X)) (kcal/(mol*Å))'\n",
    ")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Knowing the U(x), can you compute a PMF using this equation from our lecture? We sometime call this equation Boltzmann inversion because k is Boltzmann constant.\n",
    "# $\\Delta G(x)= -kTlog \\frac{P(x)}{Z} = -kTlog \\frac{\\int exp(-U(x)/kT) dx }{Z}$  eq(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup bins/windows\n",
    "binEdges=np.linspace(-6,6,25)\n",
    "binCenters=(binEdges[:-1]+binEdges[1:])/2.\n",
    "print(\"binCenters\",binCenters, \"total bins\", len(binCenters))\n",
    "xgrid=binCenters\n",
    "\n",
    "# setup kT\n",
    "kb=0.001985875 # Boltzmann constant\n",
    "Tsim=310.15\n",
    "kbT=kb*Tsim\n",
    "print(\"kT\",kbT, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: What are the meaning of the data points on your plot? Overlay with the U(x) curve, did you recover the same potential energy profile? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integral over the whole potential gives Z as the partition function (we normall don't compute it because we don't know the U(x))\n",
    "Allxx=np.linspace(-6,6,300)\n",
    "Z=np.trapz(y=np.exp(-(potFun(Allxx))/kbT), x=Allxx)\n",
    "print(\"Partition function Z is\",Z)\n",
    "\n",
    "\n",
    "# Now integral over each bin\n",
    "f=[]\n",
    "temp=[]\n",
    "tot=[]\n",
    "\n",
    "for a in np.linspace(-6,5.5,24):\n",
    "    xx=np.linspace(a,a+0.5,10)\n",
    "    prob=np.exp(-(potFun(xx))/kbT)\n",
    "    sns.scatterplot(x=xx, y=prob)\n",
    "    integral=(np.trapz(y=prob, x=xx))/Z\n",
    "    f=-kbT*np.log(integral)\n",
    "    temp.append(copy.deepcopy(f))\n",
    "\n",
    "sns.scatterplot(x=binCenters, y=temp-np.min(temp),label=\"integral over each bin using eq 1\")  \n",
    "sns.lineplot(x=xgrid,\n",
    "    y=potFun(xgrid)-np.min(potFun(xgrid)),\n",
    "    label='U(X) (kcal/mol)', color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's run an unbiased simulation. \n",
    "# For the simplicity, we will use Brownian dynamics (overdamped Langevin dynamics). Check the difference in their equations.\n",
    "# Here we pretend we don't know the underlying U(x), we want to compute PMF directly from simulated data\n",
    "# Labele x-axis and y-axis for each plot based on your understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we are simulating a water molecule moving along x-axis in air in presence of U(x)\n",
    "# diffusion constant of a water molecle in air is: .282 cm**2/s = 2.82 Å**2/fs (at 25 ºC)\n",
    "%cd /data/lyna/teaching\n",
    "import analysis_functions\n",
    "\n",
    "diffCoef=2.82*310.15/298.15 #Approximate scaling to body temperature \n",
    "\n",
    "bd_Sim=analysis_functions.Simple_1D_BD_Sim(potGradFun)\n",
    "bd_Sim.set_parameters(dict(\n",
    "    diffusionConstant=diffCoef,\n",
    "    vmax=15.0, #maximum allowed velocity before terminating simulation due to instability\n",
    "    trajectorySnapshotRate=10, # frequency of saving trajectory\n",
    "    verbose=True,\n",
    "    timestep=0.1 # fs\n",
    "))\n",
    "\n",
    "print(bd_Sim.parameter_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps=20000 # how many ns did you simulate?\n",
    "trajData=bd_Sim.run_sim(\n",
    "    nsteps=nsteps,\n",
    "    giveVelocities=True)\n",
    "print(\"Done\")\n",
    "\n",
    "# plot raw simulated data\n",
    "sns.scatterplot(x=np.arange(0, len(trajData['trajectory'])), y=trajData['trajectory'], alpha=0.2)\n",
    "plt.show()\n",
    "\n",
    "# convert raw data to histogram. Is your histogram symmetric? If not, what do you do?\n",
    "sns.histplot(trajData['trajectory'],bins=binEdges)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert histogram to PMF using Boltzmann inversion\n",
    "\n",
    "sim_pmf_hist=np.histogram(\n",
    "    a=trajData['trajectory'],\n",
    "    bins=binEdges\n",
    ")\n",
    "\n",
    "sim_pmf_vec=sim_pmf_hist[0]\n",
    "sim_pmf_vec=sim_pmf_vec/np.sum(sim_pmf_vec) # normalize histogram\n",
    "sim_pmf_vec=-kbT*np.log(sim_pmf_vec/np.max(sim_pmf_vec))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=xgrid,\n",
    "    y=sim_pmf_vec,\n",
    "    label='Raw X_Ind count PMF'\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    x=xgrid,\n",
    "    y=potFun(xgrid)-np.min(potFun(xgrid)),\n",
    "    label='U(X) (kcal/mol)'\n",
    ")\n",
    "\n",
    "plt.xlabel('X (Å)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save simulated data\n",
    "rawZ=[]\n",
    "ts=0.1 \n",
    "trajectorySnapshotRate=10  # framesize 1fs\n",
    "\n",
    "rawZ=pd.DataFrame(trajData['trajectory'],columns=['Z'])\n",
    "rawZ['time']=np.arange(0,nsteps/trajectorySnapshotRate)\n",
    "print(rawZ.head())\n",
    "rawZ.to_csv('1D-BDtraj.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comput position and velocity correlation time\n",
    "# How long it takes for each datapoint to become independent from previous data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymbar\n",
    "from pymbar import timeseries\n",
    "import pytraj as pt\n",
    "import math\n",
    "\n",
    "sns.lineplot(x=np.arange(len(trajData['velocities'])),y=pt.acorr(trajData['velocities']),marker='o')\n",
    "plt.xlim(0,5)\n",
    "plt.show()\n",
    "sns.lineplot(x=np.arange(len(trajData['trajectory'])),y=pt.acorr(trajData['trajectory']))\n",
    "sns.lineplot(x=np.arange(len(trajData['trajectory'])),y=1/math.e, label=\"1/e\")\n",
    "plt.xlim(0,100)\n",
    "plt.xlabel(\"fs\")\n",
    "plt.ylabel(\"PACF\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "corrTime=timeseries.statisticalInefficiency(trajData['trajectory'])\n",
    "print(\"positional autocorr time in fs\", (corrTime-1)/2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use your computed positional correlation time, what is the standard error of mean of your sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets calculate the averages and std as a function of time. How long does it take for your average value and standard deviation value to converge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=rawZ.Z\n",
    "ave_time=[]\n",
    "std_time=[]\n",
    "\n",
    "frame=[]\n",
    "for i in range(1,len(data),10):\n",
    "  frame.append(i)\n",
    "  ave_time.append(copy.deepcopy(np.mean(data[0:i])))\n",
    "  std_time.append(copy.deepcopy(np.sqrt(np.var(data[0:i]))))\n",
    "  \n",
    "\n",
    "sns.lineplot(frame,ave_time,label='Average')\n",
    "sns.lineplot(frame,std_time, label=\"standard deviation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a better representation of avg and std\n",
    "\n",
    "ave_upper=np.asarray(ave_time)+np.asarray(std_time)\n",
    "ave_lower=np.asarray(ave_time)-np.asarray(std_time)\n",
    "\n",
    "plt.plot(frame,ave_time,label=' Average',c='r')\n",
    "plt.fill_between(frame, ave_upper, ave_lower, color='red', alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Lets Split Our Trajectory Up Into Chunks or \"Blocks\" of Equal sizes\n",
    "def chunkIt(numFrames, numBlocks):\n",
    "    avg = numFrames / float(numBlocks)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "    while last < numFrames-1:\n",
    "        out.append([int(last),int(last+avg)])\n",
    "        last += avg\n",
    "    return out\n",
    "\n",
    "print(\"split 2000 frames into 10 blocks\", chunkIt(2000, 10))\n",
    "Ind=chunkIt(2000,10)\n",
    "block_size=(Ind[0][1]-Ind[0][0])\n",
    "print(\"Block Size:\", block_size,\"Blocks:\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on this analysis, what block size will you choose for block averaging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b_var=[]\n",
    "b_sd=[]\n",
    "b_size=[]\n",
    "b_ave=[]  \n",
    "b_stderr=[]\n",
    "frames=len(data)\n",
    "n_blocks=60 # maximum number of blocks\n",
    "for j in range(2,n_blocks,1):\n",
    " indices= chunkIt(frames,j)\n",
    " ave=[]\n",
    " for i in range(0,len(indices)):\n",
    "  ave.append((np.average(data[indices[i][0]:indices[i][1]])))\n",
    " b_ave.append((np.average(ave)))\n",
    " b_var.append((np.var(ave)))\n",
    " b_size.append((indices[0][1]-indices[0][0]))\n",
    " b_stderr.append((np.sqrt(np.var(ave)/j)))\n",
    "\n",
    "plt.plot(b_size,b_stderr)\n",
    "plt.xlabel(\"Block Size\")\n",
    "plt.ylabel(\"Standard Error\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "upper=np.asarray(b_ave)+np.asarray(b_stderr)\n",
    "lower=np.asarray(b_ave)-np.asarray(b_stderr)\n",
    "plt.plot(b_size,b_ave,color='b')\n",
    "plt.fill_between(b_size, upper, lower, color='b', alpha=0.2)\n",
    "\n",
    "plt.xlabel(\"Block Size\")\n",
    "plt.ylabel(\"Average\")\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's use your block size to compute the error bar for your PMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's add error bars from blockerror method\n",
    "\n",
    "def free_energy_1D_blockerror(a,T,x0,xmax,bins,blocks):\n",
    "  histo,xedges=np.histogram(a,bins=bins,range=[x0,xmax],density=True,weights=None)\n",
    "  max=np.max(histo)  \n",
    "  free_energy=-(0.001987*T)*np.log(histo+.000001)\n",
    "  free_energy=free_energy-np.min(free_energy)\n",
    "  xcenters= xedges[:-1] + np.diff(xedges)/2\n",
    "  \n",
    "  Ind=chunkIt(len(a),blocks)\n",
    "  block_size=(Ind[0][1]-Ind[0][0])\n",
    "  print(\"Block Size:\", block_size,\"Blocks:\",blocks)\n",
    "  \n",
    "  hist_blocks=[]\n",
    "  for i in range(0,len(Ind)):\n",
    "   block_data=a[Ind[i][0]:Ind[i][1]]\n",
    "   hist,binedges=np.histogram(block_data,bins=bins,range=[x0,xmax],density=True,weights=None)\n",
    "   hist_blocks.append(hist)\n",
    "  hist_blocks=np.array(hist_blocks)\n",
    "  average=np.average(hist_blocks,axis=0)\n",
    "  variance=np.var(hist_blocks,axis=0)\n",
    "  N=len(hist_blocks)\n",
    "  error = np.sqrt( variance / N ) \n",
    "  ferr = -(0.001987*T)*(error / average)\n",
    "  return free_energy,xcenters,ferr\n",
    "\n",
    "\n",
    "dG,bin_centers,ferr=free_energy_1D_blockerror(trajData['trajectory'], 310.15, -6.0, 6.0, binEdges,10)\n",
    "sns.lineplot(x=bin_centers,y=dG,color='blue')\n",
    "plt.fill_between(bin_centers, dG-ferr, dG+ferr, color='blue', alpha=0.2)\n",
    "\n",
    "plt.xlabel('x', size=20)\n",
    "plt.ylabel('Free Energy (kcal/mol)', size=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xticks(size='15')\n",
    "plt.yticks(size='15')\n",
    "plt.tight_layout()\n",
    "outdir=\"/data/lyna/teaching/\"\n",
    "np.savetxt(outdir+'BD.dG.err.dat',np.column_stack((bin_centers, dG,ferr)))\n",
    "plt.tight_layout()\n",
    "plt.savefig('%s/BD.dG.pdf'%outdir)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now it's your turn to run BD simulation using different timestep and diffusion constant, and plot your own well-converged PMF with nice error bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another way to run block error is to use pyblock\n",
    "#https://github.com/jsspencer/pyblock/blob/master/docs/tutorial.rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyblock in ./.local/lib/python3.7/site-packages (0.6)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 23.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --user pyblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyblock\n",
    "reblock_data = pyblock.blocking.reblock(np.asarray(data))\n",
    "for reblock_iter in reblock_data:\n",
    "    print(reblock_iter)\n",
    "    \n",
    "opt = pyblock.blocking.find_optimal_block(len(data), reblock_data)\n",
    "print(opt)\n",
    "print(reblock_data[opt[0]])\n",
    "\n",
    "data_pd=pd.Series(data)\n",
    "(data_length, reblock_data, covariance)=pyblock.pd_utils.reblock(data_pd)\n",
    "pyblock.plot.plot_reblocking(reblock_data);\n",
    "reblock_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
